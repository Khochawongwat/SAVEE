{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install kagglehub\n",
    "%pip install librosa\n",
    "%pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import read\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savee_path = kagglehub.dataset_download(\"ejlok1/surrey-audiovisual-expressed-emotion-savee\")\n",
    "cremad_path = kagglehub.dataset_download(\"ejlok1/cremad\")\n",
    "\n",
    "print(\"Path to dataset files:\", savee_path)\n",
    "print(\"Path to dataset files:\", cremad_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviates = [\"a\", \"d\", \"f\", \"h\", \"sa\", \"su\", \"n\"]\n",
    "categories = {x: i for i, x  in enumerate(abbreviates)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code(filename):\n",
    "    match = re.search(r'^[A-Z]{2}_(\\D+)\\d{2}\\.wav$', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "def extract_spectrogram(file_path, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "    return log_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs_path_1 = os.path.join(savee_path, os.listdir(savee_path)[0])\n",
    "wavs_1 = os.listdir(wavs_path_1)\n",
    "\n",
    "x_1, y_1 = [], []\n",
    "\n",
    "for wav in tqdm.tqdm(wavs_1):\n",
    "    file_path = os.path.join(wavs_path_1, wav)\n",
    "    spectrogram = extract_spectrogram(file_path)\n",
    "    code = extract_code(wav)\n",
    "    x_1.append(spectrogram)\n",
    "    y_1.append(categories[code])\n",
    "    \n",
    "wavs_path_2 = os.path.join(cremad_path, os.listdir(cremad_path)[0])\n",
    "wavs_path_2 = os.path.join(\"AudioWAV\", wavs_path_2)\n",
    "wavs_2 = os.listdir(wavs_path_2)\n",
    "\n",
    "x_2, y_2 = [], []\n",
    "cat = {\n",
    "    \"ANG\": 0,\n",
    "    \"DIS\": 1,\n",
    "    \"FEA\": 2,\n",
    "    \"HAP\": 3,\n",
    "    \"NEU\": 4,\n",
    "    \"SAD\": 6\n",
    "}\n",
    "\n",
    "rnge = 480\n",
    "\n",
    "for wav in tqdm.tqdm(wavs_2[:rnge]):\n",
    "    file_path = os.path.join(wavs_path_2, wav)\n",
    "    spectrogram = extract_spectrogram(file_path)\n",
    "    code = wav.split(\"_\")[2]\n",
    "    x_2.append(spectrogram)\n",
    "    y_2.append(cat[code])\n",
    "\n",
    "max_length = max(max([spec.shape[1] for spec in x_1]), max([spec.shape[1] for spec in x_2]))\n",
    "\n",
    "x_1 = np.array([np.pad(spec, ((0, 0), (0, max_length - spec.shape[1])), mode='constant', constant_values=np.min(spec)) for spec in x_1])\n",
    "y_1 = np.array(y_1)\n",
    "\n",
    "x_2 = np.array([np.pad(spec, ((0, 0), (0, max_length - spec.shape[1])), mode='constant', constant_values=np.min(spec)) for spec in x_2])\n",
    "y_2 = np.array(y_2)\n",
    "\n",
    "x = np.concatenate((x_1, x_2[:rnge]), axis=0)\n",
    "y = np.concatenate((y_1, y_2[:rnge]), axis=0)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, counts = np.unique(y, return_counts=True)\n",
    "classes, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_classes = classes[classes != 5]\n",
    "filtered_counts = counts[classes != 5]\n",
    "y_mask = np.isin(y, filtered_classes)\n",
    "x = x[y_mask]\n",
    "y = y[y_mask]\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "classes, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since class imbalance could cause us to misunderstand our accuracies, we should undersample or oversample our classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since surprise didnt have enough, we will just remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_class_size = min(counts)\n",
    "\n",
    "x_list, y_list = list(x), list(y)\n",
    "class_to_samples = {label: [] for label in np.unique(y)}\n",
    "for spec, label in zip(x_list, y_list):\n",
    "    class_to_samples[label].append(spec)\n",
    "\n",
    "x_balanced, y_balanced = [], []\n",
    "for label, samples in class_to_samples.items():\n",
    "    undersampled_samples = resample(\n",
    "        samples, n_samples=min_class_size, random_state=42, replace=False\n",
    "    )\n",
    "    x_balanced.extend(undersampled_samples)\n",
    "    y_balanced.extend([label] * min_class_size)\n",
    "\n",
    "x = np.array(x_balanced)\n",
    "y = np.array(y_balanced)\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must convert waves into spectrograms to reduce dimensionality. If you want to see what this means try removing extract_spectrogram(). You will see that the maximum length will be 300k. This is extremely high and the model will likely not be able to train due to the load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(x[0], aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title(\"Spectrogram\")\n",
    "plt.xlabel(\"Time Frames\")\n",
    "plt.ylabel(\"Mel Frequency Bands\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a spectrogram. It is a representation of frequencies of a signal over time. We can do extract alot of features based on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr(x):\n",
    "    return np.squeeze(librosa.feature.zero_crossing_rate(x))\n",
    "\n",
    "def rms(x):\n",
    "    return np.squeeze(librosa.feature.rms(y = x))\n",
    "\n",
    "def mfcc(x):\n",
    "    return np.ravel(librosa.feature.mfcc(y=x).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(rms(x[0]))\n",
    "plt.title(\"RMS\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"RMS Energy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(zcr(x[0]), label='Zero Crossing Rate', color='r')\n",
    "plt.title('Zero crossing rate')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude / ZCR')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    result = np.array([])\n",
    "    result = np.hstack((result, np.mean(x), np.std(x)))\n",
    "    result = np.hstack((result, zcr(x)))\n",
    "    result = np.hstack((result, rms(x)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([extract_features(spec) for spec in x])\n",
    "x.shape, y.shape, features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we add features to our training sample, lets try training only with spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_normalized = np.array([scaler.fit_transform(k) for k in x])\n",
    "x_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor(x_normalized, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype = torch.int64)\n",
    "\n",
    "x_tensor.shape, y_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_tensor, y_tensor, test_size=0.3, random_state=42)\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        #We use bidirectional so the hidden-size is *2 so this needs to be hidden_size * 2\n",
    "        #Bidirectional is like 2 models stuck together where each overlap and shifts left and right\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = LSTMClassifier(308, 128, len(classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00002)\n",
    "\n",
    "best_accuracy = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            running_test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    avg_test_loss = running_test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    if accuracy < best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "labels = list(range(len(classes)))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap='viridis', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the two curves still are pointing down so we could train longer if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        #WE use bidirectional so the hidden-size is *2 so this needs to be hidden_size * 2\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        weights = torch.softmax(self.attention(x), dim=1) \n",
    "        context = torch.sum(weights * x, dim=1)\n",
    "        return context, weights\n",
    "\n",
    "class LSTMAttentionClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, conv_kernel_size=3):\n",
    "        super(LSTMAttentionClassifier, self).__init__()\n",
    "        \n",
    "        #This is our feature extraction layer here.\n",
    "        self.conv = nn.Conv1d(in_channels=input_size, \n",
    "                              out_channels=hidden_size, \n",
    "                              kernel_size=conv_kernel_size, \n",
    "                              padding=conv_kernel_size // 2)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        #Attention is basically what the area where the model can focus on.\n",
    "        self.attention = Attention(hidden_size)\n",
    "        \n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, weights = self.attention(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.fc(x)\n",
    "        return x, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "model = LSTMAttentionClassifier(308, 128, len(classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00002)\n",
    "\n",
    "best_accuracy = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output, _ = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            running_test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    avg_test_loss = running_test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    if accuracy < best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "data, _ = next(iter(test_loader))\n",
    "data = data.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output, weights = model(data)\n",
    "\n",
    "weights = weights[0].cpu().numpy()\n",
    "\n",
    "input_data = data[0].cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(input_data, aspect='auto', cmap='Blues')\n",
    "plt.imshow(weights[np.newaxis, :], aspect='auto', cmap='Reds', alpha=0.7)\n",
    "plt.colorbar(label=\"Input Features\")\n",
    "plt.colorbar(label=\"Attention Weights\")\n",
    "plt.title(\"Attention Overlay\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the attention is focused at the end of the sequence. So this could mean that frequencies at the end could correlate well with the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output, _ = model(data)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "labels = list(range(len(classes)))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap='viridis', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try adding the previosly extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([extract_features(spec) for spec in x])\n",
    "features = features[:, np.newaxis, :] \n",
    "features = np.repeat(features, x.shape[1], axis=1)\n",
    "#We add a new axis to turn features into (420, 1, 2818) before repeating 12 times to be (420, 12, 2818)\n",
    "x.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_with_features = np.concatenate([x, features], axis=2)\n",
    "x_with_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = torch.tensor(x_with_features, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype = torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_tensor, y_tensor, test_size=0.3, random_state=42)\n",
    "y_train = y_train.squeeze()\n",
    "y_test = y_test.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(x_with_features.shape[-1], 128, len(classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.00002)\n",
    "\n",
    "best_accuracy = float('inf')\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            running_test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    avg_test_loss = running_test_loss / len(test_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    if accuracy < best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is self explanatory. Perhaps more features does not mean better performance with deep learning models. Though we can reduce the dimensionality by using PCA but it is not within the scope. Since the simple model does not work then the complex does not need to be checked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try traditional algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "X = x_with_features.reshape(x_with_features.shape[0], -1) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Time taken {time.time() - start_time}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X = x.reshape(x.shape[0], -1) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Time taken {time.time() - start_time}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFC actually works much better than both DL models even including the complex attention model. We can also conclude that adding features does indeed increase the accuracy with the cost of training time of 2x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If RFC works then how about gradient boosting algorithms? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "X = x_with_features.reshape(x_with_features.shape[0], -1) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state=42, verbosity = 0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Time taken {time.time() - start_time}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "X = x.reshape(x.shape[0], -1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = lgb.LGBMClassifier(random_state=42, verbosity = 0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Time taken: {time.time() - start_time} seconds\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the LGM works even better than RFC. However, the training time is 50x that of RFC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that traditional ML works the best with LGM Classifier using fequency derived features having the best accuracy at 45.24% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
